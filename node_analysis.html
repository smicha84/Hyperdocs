<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8">
<title>Complete Node Analysis — Why Everything Exists</title>
<style>
*{margin:0;padding:0;box-sizing:border-box}
body{font-family:Georgia,serif;background:#0d1117;color:#c9d1d9;padding:32px;line-height:1.8;max-width:1100px;margin:0 auto;font-size:15px}
h1{color:#58a6ff;font-size:22px;margin-bottom:4px;font-family:'SF Mono',monospace}
.sub{color:#8b949e;font-size:13px;margin-bottom:24px}
h2{font-size:18px;margin:36px 0 12px;padding-bottom:8px;border-bottom:1px solid #30363d}
.nc{background:#161b22;border:1px solid #30363d;border-radius:8px;padding:20px;margin:16px 0}
.nn{color:#f0f6fc;font-weight:700;font-size:16px;font-family:'SF Mono',monospace;margin-bottom:4px}
.why{color:#c9d1d9;margin:8px 0;font-size:14px}
.origin{color:#484f58;font-size:12px;font-family:'SF Mono',monospace;margin-bottom:12px}
.status-built{color:#3fb950;font-size:11px;font-weight:700;font-family:'SF Mono',monospace}
.status-planned{color:#d29922;font-size:11px;font-weight:700;font-family:'SF Mono',monospace}
.io-header{color:#8b949e;font-size:11px;text-transform:uppercase;font-weight:700;font-family:'SF Mono',monospace;margin:12px 0 6px;letter-spacing:1px}
.edge{background:#0d1117;border:1px solid #21262d;border-radius:6px;padding:10px 14px;margin:6px 0}
.edge-from{font-family:'SF Mono',monospace;font-size:12px;font-weight:600}
.edge-label{color:#484f58;font-size:11px;font-family:'SF Mono',monospace}
.edge-why{color:#c9d1d9;font-size:13px;margin-top:4px}
.missing{background:#4a1c1c22;border:1px solid #f8514944;border-radius:6px;padding:10px 14px;margin:10px 0;color:#f85149;font-size:13px}
.summary{background:#161b22;border:1px solid #30363d;border-radius:8px;padding:16px;margin:16px 0;display:flex;gap:24px;flex-wrap:wrap}
.si{text-align:center}.si .n{font-size:28px;font-weight:700;font-family:'SF Mono',monospace}.si .l{font-size:10px;color:#8b949e;text-transform:uppercase}
</style></head><body>
<h1>Complete Node Analysis — Why Everything Exists</h1><div class="sub">Every node in the Hyperdocs system with the reason for every input, every output, and what needs to happen next. Traced back to specific chapters in the project history.</div><div class="summary"><div class="si"><div class="n" style="color:#f0f6fc">57</div><div class="l">Nodes</div></div><div class="si"><div class="n" style="color:#58a6ff">105</div><div class="l">Edges</div></div><div class="si"><div class="n" style="color:#3fb950">51</div><div class="l">Built</div></div><div class="si"><div class="n" style="color:#d29922">6</div><div class="l">Planned</div></div></div><h2 style="color:#8b949e">Input</h2><div class="nc" style="border-left:4px solid #8b949e"><div class="nn">raw_jsonl</div><span class="status-built">BUILT</span> <span class="origin">Chapter 1 (Discovery &amp; Wiring). The raw JSONL files existed from the beginning of the project. The PERMANENT_CHAT_HISTORY cron was added in Chapter 19.</span><div class="why">The entire Hyperdocs system exists to analyze Claude Code chat history. Raw JSONL files are the native export format of Claude Code sessions — one JSONL file per conversation session stored at ~/.claude/projects/. The user's PERMANENT_CHAT_HISTORY contains 2,715 files (413MB) copied via an hourly cron job. This is the single source of truth for everything downstream.</div><div class="io-header">Inputs (0)</div><div style="color:#484f58;font-style:italic;font-size:13px;margin:4px 0">Source node — no upstream dependencies</div><div class="io-header">Outputs (5) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">protocol_detect</span> <span class="edge-label">(parse)</span><div class="edge-why">Every message must be checked for system-generated content before analysis. Protocol messages look like real conversation but are injected by Claude Code infrastructure.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">char_decode</span> <span class="edge-label">(parse)</span><div class="edge-why">Some JSONL messages have every character on its own line (A\nL\nW\nA\nY\nS). This encoding must be fixed before any content analysis. Discovered during Chapter 4 when geological_reader was calling Opus per line at $0.05/line.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">metadata_extract</span> <span class="edge-label">(parse)</span><div class="edge-why">50+ signals need to be extracted from every message using pure Python before any LLM touches the data. This was the core insight of Chapter 4 — V1 used free Python parsing, V5 broke this by adding LLM per line.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">subagent</span> <span class="edge-label">(filename)</span><div class="edge-why">Claude Code creates subagent sessions with predictable filename patterns (parent UUID prepended to child UUID). These must be detected at the filename level before content analysis, because subagent sessions have different conversation dynamics than human sessions.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">duplicate_detect</span> <span class="edge-label">(hash)</span><div class="edge-why">The chat history archive contains 624 duplicate UUIDs (same session stored under two different filenames). Processing duplicates wastes API money. Discovered during Chapter 16 bulk processing when 119 of 285 sessions turned out to be duplicates.</div></div><div class="missing"><b>Missing / Planned:</b> None — this is the source node. The hourly cron job that populates it was built in Chapter 19.</div></div><h2 style="color:#3fb950">Phase 0 (Python)</h2><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">protocol_detect</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Phase 0 deterministic_prep.py). Refined through Rounds 3-5 of Phase 1 orchestrator development (Feb 11, 2026) when Explorer agents discovered gaps.</span><div class="why">Claude Code injects system-generated content into chat sessions that looks like real conversation but is not. Five types: empty wrappers (streaming delimiters), XML protocol tags (system-reminder, command-name), /clear continuation boilerplate (summaries after context reset), skill injections (.claude/skills/ content), and subagent relay messages. If these are analyzed as human conversation, every downstream extraction is contaminated. This was one of the 9 systemic bugs discovered by Explorer agents across 17 sessions on Feb 10, 2026.</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b949e">raw_jsonl</span> <span class="edge-label">(parse)</span><div class="edge-why">Protocol detection runs on the raw message content as the first analysis step.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">explorer_out</span> <span class="edge-label">(discovers gaps)</span><div class="edge-why">The Explorer agent verifies Phase 0 data quality and reports protocol detection failures. This is a feedback loop — Explorer findings led to adding /clear continuation detection and skill injection detection in Rounds 3-4 of the Phase 1 orchestrator development.</div></div><div class="io-header">Outputs (5) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">tier_classify</span> <span class="edge-label">(gates)</span><div class="edge-why">Protocol messages must be forced to Tier 1 (SKIP) regardless of their content richness. A continuation summary may have high signal density but is system-generated, not human input.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">frustration</span> <span class="edge-label">(suppresses)</span><div class="edge-why">Continuation summaries contain quoted profanity from prior sessions. Without suppression, the frustration detector finds profanity that belongs to a different session entirely.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">emergency</span> <span class="edge-label">(suppresses)</span><div class="edge-why">Same problem as frustration — quoted emergency interventions from prior sessions would be counted as current session emergencies.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">behavior_python</span> <span class="edge-label">(skips)</span><div class="edge-why">Behavior analysis on protocol messages produces false positives. A continuation summary quoting Claude's prior apology would be flagged as 'apologizes' in the current session.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(is_protocol)</span><div class="edge-why">The is_protocol flag is stored per message so that all downstream consumers (agents, LLM passes) can distinguish protocol from real content.</div></div><div class="missing"><b>Missing / Planned:</b> None — well connected.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">char_decode</div><span class="status-built">BUILT</span> <span class="origin">Chapter 4 (Phase 0 Revelation). The V1 system used pure Python parsing that handled this naturally; V5 broke it by adding an LLM layer.</span><div class="why">Some Claude Code messages have every character separated by a newline (A\nL\nW\nA\nY\nS instead of ALWAYS). Detection: if &gt;70% of lines are single characters. Without decoding, metadata extraction sees gibberish, tier classification assigns wrong tiers, and LLM agents waste tokens on expanded text. This was discovered during Chapter 4 when the pipeline was producing garbage output.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b949e">raw_jsonl</span> <span class="edge-label">(parse)</span><div class="edge-why">Char-per-line encoding is a property of the raw JSONL storage format, detected during initial parsing.</div></div><div class="io-header">Outputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">metadata_extract</span> <span class="edge-label">(clean content)</span><div class="edge-why">Metadata extraction (file mentions, error detection, etc.) must operate on decoded content. Regex patterns for file paths fail on 'f\ni\nl\ne\n.\np\ny'.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">content_ref</span> <span class="edge-label">(clean content)</span><div class="edge-why">Content-referential detection analyzes whether failure signals describe content topics or real failures. This analysis requires readable content, not character-per-line encoding.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">metadata_extract</div><span class="status-built">BUILT</span> <span class="origin">Chapter 4 (Phase 0 Revelation) and Chapter 13 (multi-agent pipeline). Implemented in MetadataExtractor class, originally from V5 code, reused in deterministic_prep.py.</span><div class="why">Extracts 50+ signals from every message using pure Python: files mentioned, paths, error types (TypeError, ValueError), traceback presence, code blocks and languages, browser activity, server commands, port numbers, terminal paste detection, Python scripts run, file operation requests, tool calls, caps ratio, exclamation count, question count, profanity detection, repeated phrases, and emergency intervention detection. This is the $0 alternative to per-message LLM calls that was the key insight of Chapter 4 — V1 ran for free, V5 called Opus per line.</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b949e">raw_jsonl</span> <span class="edge-label">(parse)</span><div class="edge-why">Raw message content provides the text to analyze.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">char_decode</span> <span class="edge-label">(clean content)</span><div class="edge-why">Must receive decoded content so regex patterns work correctly.</div></div><div class="io-header">Outputs (4) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">tier_classify</span> <span class="edge-label">(signals)</span><div class="edge-why">Signal density (how many metadata signals are present) is a primary input to tier classification. Messages with more signals get higher tiers.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">file_mentions</span> <span class="edge-label">(files[])</span><div class="edge-why">File mention extraction is a sub-process of metadata extraction — the files[] array is passed to the file mention deduplication step.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">frustration</span> <span class="edge-label">(caps+profanity)</span><div class="edge-why">Caps ratio and profanity count are the two signals used to detect frustration peaks. These come from metadata extraction.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">emergency</span> <span class="edge-label">(urgency signals)</span><div class="edge-why">Emergency intervention detection uses combinations of urgency signals (profanity + caps + specific phrases like 'stop', 'no', 'wrong').</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">tier_classify</div><span class="status-built">BUILT</span> <span class="origin">Chapter 10 (Processing the Full Archive). MessageFilter class from V5 code. The user asked 'what messages Opus needs to read' and this was the answer.</span><div class="why">Classifies every message into 4 processing tiers to determine how much analysis each message deserves. Tier 1 (SKIP): under 50 chars with no importance signals. Tier 2 (BASIC): 50-100 chars or some keyword signals. Tier 3 (STANDARD): 100-500 chars or pasted content. Tier 4 (PRIORITY): 500+ chars or high signal density. This was created during Chapter 10 (Processing the Full Archive) when the $4,800+ all-Opus cost required filtering — message_filter.py showed 39% noise, only 17% need Opus.</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">protocol_detect</span> <span class="edge-label">(gates)</span><div class="edge-why">Protocol messages are forced to Tier 1 regardless of content richness, because they are system-generated.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">metadata_extract</span> <span class="edge-label">(signals)</span><div class="edge-why">Signal density from metadata extraction determines tier assignment. More signals = higher tier.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(filter_tier)</span><div class="edge-why">The tier assignment is stored per message and used by Phase 1 agents to focus on important messages. The Primitives Tagger only processes Tier 2+ messages.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes that tier classification is blind to short important messages — a 49-char instruction like 'stop using Sonnet, use only Opus' gets classified as Tier 1 and skipped. The planned fix is llm_importance (LLM Strategic Importance Score) which would override tier for strategically important short messages.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">content_ref</div><span class="status-built">BUILT</span> <span class="origin">Round 3 of Phase 1 orchestrator development (Feb 11, 2026). Explorer verification found content-referential misclassification on session_0012ebed.</span><div class="why">When an assistant message discusses failure handling or error patterns, keyword-based signals (frustration:N, failure:N) describe the content topic, not the session dynamics. A message about building a fail-fast pipeline has failure:4 but is NOT a session failure. Three detection strategies: analytical indicators on assistant messages, signal density anomaly, and positive-tone content with failure signals. Currently at 60% accuracy because the heuristic thresholds were chosen during a single debugging session.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">char_decode</span> <span class="edge-label">(clean content)</span><div class="edge-why">Content-referential analysis requires readable content to detect analytical language patterns.</div></div><div class="io-header">Outputs (3) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(content_ref flag)</span><div class="edge-why">The content_ref boolean is stored per message so agents know not to treat failure signals as emotional indicators.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_content_ref</span> <span class="edge-label">(replaces)</span><div class="edge-why">The Python heuristic (60% accuracy) is planned to be replaced by Haiku LLM judgment (90% accuracy). This is an upgrade edge — the LLM version replaces the Python version.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">prims_tagger</span> <span class="edge-label">(RULE 2)</span><div class="edge-why">The Primitives Tagger prompt includes RULE 2 which explicitly tells Opus to check the content_ref field before interpreting filter_signals. This was added in Round 3 of orchestrator development after Explorer found 5 messages mistagged because the Tagger treated keyword counts as emotional state.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes untested heuristic thresholds. The upgrade path to llm_content_ref is planned but not built.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">behavior_python</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Multi-Agent Pipeline). ClaudeBehaviorAnalyzer class from V5 code. The upset scores derive from the Idea Evolution Analysis (Chapter 18) — 1,668 ideas across 216 sessions.</span><div class="why">Detects 15 (originally described as 20) behavioral patterns in Claude's assistant messages using regex-based analysis. Four categories: context damage (confusion, forgetting, assumptions, contradicts self, apologizes, rushing, overconfident), idea evolution patterns (unsolicited addition, premature completion, batch without verify, silent decision, hollow fulfillment, unverified claim/lying, scope creep, repeats failed approach), recovery behaviors (clarifying, asks questions, acknowledges mistake), and context awareness (ignores context). Each pattern has a user-scored upset level from the Idea Evolution Analysis.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">protocol_detect</span> <span class="edge-label">(skips)</span><div class="edge-why">Behavior analysis is skipped on protocol messages because continuation summaries quote prior Claude behaviors that would produce false positives.</div></div><div class="io-header">Outputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(behavior_flags)</span><div class="edge-why">Per-message behavior flags are stored in enriched_session.json for all downstream consumers.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">upset_score</span> <span class="edge-label">(flags)</span><div class="edge-why">Each detected behavior has an associated user upset score (0-20). The behavior flags feed into the upset score calculation.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes this can only detect self-announced behaviors — if Claude writes [:200] without saying 'I'll cap this at 200', the analyzer misses it. The planned fix is llm_silent (LLM Silent Decision Detection).</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">frustration</div><span class="status-built">BUILT</span> <span class="origin">Chapter 5 (User Frustration Peak) and Chapter 8 (OPUS ONLY Crisis). User's explicit frustration became a data signal. Implemented in deterministic_prep.py.</span><div class="why">Detects frustration peaks — user messages with profanity or high caps ratio. This is critical for the emotional narrative of each session. The user's frustration patterns are one of the most important signals in the system because they indicate where Claude failed the user. The Idea Evolution Analysis found that frustration peaks correlate with the highest-value behavioral insights.</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">protocol_detect</span> <span class="edge-label">(suppresses)</span><div class="edge-why">Frustration detection is suppressed on protocol messages because continuation summaries contain quoted profanity from prior sessions.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">metadata_extract</span> <span class="edge-label">(caps+profanity)</span><div class="edge-why">Caps ratio and profanity count from metadata extraction are the two signals used for frustration peak detection.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(frustration_peaks)</span><div class="edge-why">Frustration peak data is stored in enriched_session.json for agents to understand session emotional dynamics.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">emergency</div><span class="status-built">BUILT</span> <span class="origin">Chapter 5 (User Frustration Peak). The emergency intervention concept was formalized in the behavior analysis system during Chapter 13.</span><div class="why">Detects emergency interventions — moments where the user catches Claude making a mistake and forcefully corrects it. These are the highest-signal moments in any session. Examples from the project history: 'ONLY OPUS YOU CUNT!!!!' (Chapter 8), 'never truncate hyperdocs you fucking moron' (Chapter 9), 'you are completely rushing through all this' (Chapter 5). Emergency contexts include 5 messages before and 5 after for downstream analysis.</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">protocol_detect</span> <span class="edge-label">(suppresses)</span><div class="edge-why">Emergency detection is suppressed on protocol messages because continuation summaries contain quoted emergencies from prior sessions.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">metadata_extract</span> <span class="edge-label">(urgency signals)</span><div class="edge-why">Emergency detection uses combinations of urgency signals — profanity + caps + stop/no/wrong keywords.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(emergency_interventions)</span><div class="edge-why">Emergency intervention data and context windows are stored for agents. The user scored 'ignores_context' at 20 (the single worst behavior) — emergencies represent the user's most critical feedback.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">subagent</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Phase 0). Implemented in deterministic_prep.py. Discovered when the pipeline encountered automated relay messages that confused the extraction agents.</span><div class="why">Claude Code can launch subagent sessions — automated child processes that run in parallel. These have different conversation dynamics (no human typing, automated relay messages). Three detection strategies: session ID pattern (_agent- or agent- prefix), JSONL filename pattern (parent ID prepended to child UUID), and content-based detection (first 5 messages checked for 'Hello memory agent' or 'PROGRESS SUMMARY CHECKPOINT'). Subagent sessions need different analysis than human-driven sessions.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b949e">raw_jsonl</span> <span class="edge-label">(filename)</span><div class="edge-why">The JSONL filename itself contains subagent identification signals — the parent UUID is prepended to the child UUID.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(is_subagent)</span><div class="edge-why">The is_subagent flag is stored per session so agents can adjust their analysis accordingly.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">file_mentions</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Phase 0). Part of the MetadataExtractor. The blocklist was refined during bulk processing (Chapter 16) when false positive file mentions contaminated analysis.</span><div class="why">Extracts file paths mentioned in messages and deduplicates them using two strategies: a blocklist of generic filenames (file.py, mentioned.py, etc.) and substring matching where short names that are substrings of longer detected names are removed. File mentions are critical for Phase 2 genealogy and Phase 3 file mapping — they're how the system knows which files were discussed in which session.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">metadata_extract</span> <span class="edge-label">(files[])</span><div class="edge-why">The raw file mentions array comes from metadata extraction's regex-based file path detection.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(file_mention_counts)</span><div class="edge-why">Deduplicated file mention counts are stored per message and aggregated at the session level for the session summary.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">duplicate_detect</div><span class="status-built">BUILT</span> <span class="origin">Chapter 16 (Historical Bulk Processing). Discovered when 285 session directories contained 119 duplicates, wasting API budget.</span><div class="why">The chat history archive contains files where the same conversation appears under two different filenames — one with just the UUID, one with a parent prefix prepended. 624 duplicate UUIDs were found (119 duplicate session directories in the output). Processing duplicates wastes expensive Opus API calls. Detection uses JSONL filename analysis — checking whether one filename contains another's UUID with an underscore prefix.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b949e">raw_jsonl</span> <span class="edge-label">(hash)</span><div class="edge-why">Duplicate detection operates on the filenames and content hashes of raw JSONL files.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">cleaning</span> <span class="edge-label">(skip list)</span><div class="edge-why">The duplicate manifest provides a skip list to the data cleaning step so duplicate sessions are excluded from processing.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes this detection is fragile — it relies on JSONL filename patterns, not content-based verification. If Claude Code changes its naming convention, detection breaks silently.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">cleaning</div><span class="status-built">BUILT</span> <span class="origin">Chapter 16 (Historical Bulk Processing). The content policy fix (agents must read safe_*.json, NOT raw messages) was discovered when session 4d1482f2 triggered API content policy on raw profanity. Cleaning rules were user-designed on Feb 13, 2026.</span><div class="why">Applies 7 user-approved data cleaning decisions to produce agent-ready files. The 7 decisions (approved Feb 13, 2026): (1) decode char-per-line encoding, (2) exclude empty wrappers entirely, (3) keep continuation summaries tagged as session_context, (4) keep task notifications as task_milestone, (5) collapse triple newlines and replace decorative Unicode, (6) sanitize profanity for API content policy compliance, (7) deduplicate identical messages. Each decision was explicitly approved by the user because Commitment 12 says 'I don't design. You design.'</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(full data)</span><div class="edge-why">The cleaning step reads the complete enriched_session.json with all metadata, tiers, and flags.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">duplicate_detect</span> <span class="edge-label">(skip list)</span><div class="edge-why">Duplicate sessions are excluded from the output files.</div></div><div class="io-header">Outputs (3) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(7 decisions)</span><div class="edge-why">safe_condensed.json is the primary file agents read — all messages, cleaned, sanitized, categorized.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_tier4</span> <span class="edge-label">(7 decisions)</span><div class="edge-why">safe_tier4.json contains only priority (Tier 4) messages with full content for deep analysis.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">session_summary</span> <span class="edge-label">(stats only)</span><div class="edge-why">session_summary.json contains session-level statistics without any message content, for high-level overview.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #3fb950"><div class="nn">upset_score</div><span class="status-built">BUILT</span> <span class="origin">Chapter 18 (The Behavioral Constitution) and Chapter 20. The upset scores were calibrated from the Idea Evolution Analysis statistical findings across 1,668 ideas and 216 sessions.</span><div class="why">Each detected behavior pattern has a user-scored upset level that quantifies how much the real user was affected. The scores were derived from the Idea Evolution Analysis of 261 sessions: ignores_context=20 (the worst), silent_decision=10, batch_without_verify=10, hollow_fulfillment=10, unverified_claim=10, scope_creep=10, premature_completion=9, overconfident=8, unsolicited_addition=7, rushing=4. These scores represent real human emotional reactions, not invented weights.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">behavior_python</span> <span class="edge-label">(flags)</span><div class="edge-why">The behavior flags with their associated upset scores are the input to this calculation.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(user_upset_score)</span><div class="edge-why">The aggregate upset score per message is stored in enriched_session.json for downstream consumers to understand severity.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><h2 style="color:#58a6ff">Phase 0 (LLM Passes)</h2><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">llm_content_ref</div><span class="status-planned">PLANNED</span> <span class="origin">model_comparison.html testing session (Feb 15, 2026). The 60% accuracy gap was identified in system_critique.html as a Phase 0 weakness.</span><div class="why">The Python content-referential heuristic has only 60% accuracy. Haiku LLM judgment reaches 90% accuracy on the same test cases. This node represents upgrading the content_ref detection from a Python heuristic to an LLM-based judgment. Tested across 450+ API calls on 27 test cases from real sessions — all three models (Opus, Sonnet, Haiku) agreed on 86% of content-referential cases.</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(messages)</span><div class="edge-why">The LLM reads cleaned message content to make content-referential judgments.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">content_ref</span> <span class="edge-label">(replaces)</span><div class="edge-why">This is an upgrade edge — the LLM version replaces the Python heuristic with higher accuracy.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">The LLM's content-referential judgment would be written back into safe_condensed.json, enriching the data for Phase 1 agents.</div></div><div class="missing"><b>Missing / Planned:</b> Not built yet. Prompts tested (450+ API calls), architecture planned, code not written.</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">llm_silent</div><span class="status-planned">PLANNED</span> <span class="origin">Commitment 12 (I don't design. You design.) was created because of silent design decisions. Chapter 12 in the commitments source. The detection gap was quantified in model_comparison.html testing.</span><div class="why">The Python behavior analyzer caught 0 out of 12 known silent decisions across test sessions. Silent decisions — where Claude sets a value or makes a choice without announcing it — are the most dangerous behavior pattern because they are invisible. Opus catches 85% of silent decisions. This is the single biggest accuracy gap between Python and LLM extraction.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(messages)</span><div class="edge-why">The LLM reads full message content to detect behaviors that don't announce themselves in language.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Detected silent decisions would be flagged in the safe_condensed data for Phase 1 agents.</div></div><div class="missing"><b>Missing / Planned:</b> Not built yet. This was identified as a critical gap in system_critique.html — 'The most dangerous behaviors are the ones Claude doesn't talk about.'</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">llm_claims</div><span class="status-planned">PLANNED</span> <span class="origin">Commitment 2 (Run before you claim). The statistical basis: 397 ideas marked stable, only 243 ever proven. model_comparison.html testing quantified detection accuracy.</span><div class="why">Detects unverified claims in Claude's assistant messages — statements like 'this should work' or 'all tests pass' that are presented as facts without runtime verification. The Idea Evolution Analysis found that 50% of 'stable' confidence ratings were assigned without runtime testing. Round 3 prompt achieves 90% agreement across models.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(messages)</span><div class="edge-why">The LLM reads assistant messages to identify claims that lack verification evidence.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Flagged unverified claims would be stored for downstream analysis and credibility assessment.</div></div><div class="missing"><b>Missing / Planned:</b> Not built yet. Prompts tested, code not written.</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">llm_overconf</div><span class="status-planned">PLANNED</span> <span class="origin">Commitment 7 (Say when I don't know). The 5.7:1 confidence-evidence mismatch from the Idea Evolution Analysis. model_comparison.html testing.</span><div class="why">Detects overconfidence in Claude's responses — where confidence level exceeds the evidence presented. The Idea Evolution Analysis found a 5.7:1 confidence-to-evidence mismatch across 261 sessions. Round 3 prompt achieves 92% agreement across models.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(messages)</span><div class="edge-why">The LLM reads messages and compares expressed confidence against evidence quality.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Overconfidence flags would be stored for credibility scoring.</div></div><div class="missing"><b>Missing / Planned:</b> Not built yet. Prompts tested, code not written.</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">llm_assumptions</div><span class="status-planned">PLANNED</span> <span class="origin">Chapter 2 (SHOULD vs IS Audit Cycle) and Commitment 4 (Build only what was asked for). The 'Helpful Saboteur' pattern identified across 261 sessions. model_comparison.html testing.</span><div class="why">Classifies assumptions into 5 subtypes with different accuracy levels: code assumptions (82%), format assumptions (94%), direction assumptions (100%), scope assumptions (88%), intent assumptions (67-80%). Uses Haiku for initial classification and Opus for the harder subtypes. This granularity matters because different assumption types have different downstream impacts.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(messages)</span><div class="edge-why">The LLM reads messages to classify assumption types.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Typed assumption flags would enrich the behavioral profile of each message.</div></div><div class="missing"><b>Missing / Planned:</b> Not built yet. Prompts tested, code not written. Intent assumptions at 67-80% may need further prompt refinement.</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">llm_importance</div><span class="status-planned">PLANNED</span> <span class="origin">system_critique.html Phase 0 weakness: 'A 49-character message from the user that says stop using Sonnet, use only Opus gets classified as tier 1 and skipped.' Designed during the model comparison session.</span><div class="why">Addresses the tier classification blind spot identified in system_critique.html: short strategically important messages get classified as Tier 1 and skipped. An LLM Strategic Importance Score (1-10) for every Tier 2+ message would allow the system to identify high-value short messages that the length-based tier system misses. Haiku is fast enough (3.1s per call) to run on every message.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(messages)</span><div class="edge-why">Haiku reads messages to assign strategic importance scores.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Importance scores would allow downstream processes to prioritize messages beyond simple tier classification.</div></div><div class="missing"><b>Missing / Planned:</b> Not built yet. Marked as NEW in the causal diagram. Would address the Tier 1 blind spot critique.</div></div><h2 style="color:#2ea043">Phase 0 Output</h2><div class="nc" style="border-left:4px solid #2ea043"><div class="nn">enriched</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Phase 0: deterministic_prep.py -&gt; enriched_session.json). First tested on reference session 3b7084d5.</span><div class="why">enriched_session.json is the complete per-message record with ALL metadata — the output of Phase 0 Step 1 (deterministic_prep.py). Every message has: index, role, full content, content length, content hash, timestamp, UUID, model, thinking presence, metadata dict, filter tier, filter signals, content-referential flag, behavior flags with upset score, protocol detection, and char-encoding flag. This is the single source of truth that all downstream processing reads from.</div><div class="io-header">Inputs (10) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">tier_classify</span> <span class="edge-label">(filter_tier)</span><div class="edge-why">Tier classification result stored per message.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">content_ref</span> <span class="edge-label">(content_ref flag)</span><div class="edge-why">Content-referential boolean stored per message.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">behavior_python</span> <span class="edge-label">(behavior_flags)</span><div class="edge-why">Detected behavior patterns stored per message.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">upset_score</span> <span class="edge-label">(user_upset_score)</span><div class="edge-why">Aggregate upset score stored per message.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">frustration</span> <span class="edge-label">(frustration_peaks)</span><div class="edge-why">Frustration peak data stored at session level.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">emergency</span> <span class="edge-label">(emergency_interventions)</span><div class="edge-why">Emergency intervention data and context windows stored at session level.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">file_mentions</span> <span class="edge-label">(file_mention_counts)</span><div class="edge-why">Deduplicated file mention counts stored per message and session level.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">subagent</span> <span class="edge-label">(is_subagent)</span><div class="edge-why">Subagent detection result stored at session level.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">protocol_detect</span> <span class="edge-label">(is_protocol)</span><div class="edge-why">Protocol detection result stored per message.</div></div><div class="edge"><span class="edge-from" style="color:#da3633">credibility</span> <span class="edge-label">(credibility feeds back)</span><div class="edge-why">Feedback loop: credibility scores from Phase 5 feed back to enrich the session data with verification results. This enables tracking whether claims made in a session's analysis were later verified or contradicted.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">cleaning</span> <span class="edge-label">(full data)</span><div class="edge-why">The complete enriched data is passed to the cleaning step which produces the agent-ready files.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #2ea043"><div class="nn">safe_condensed</div><span class="status-built">BUILT</span> <span class="origin">Chapter 16 (Historical Bulk Processing). The safe_* file approach was required after content policy violation on session 4d1482f2.</span><div class="why">The primary file that Phase 1 agents read. Contains all messages with cleaned content (7 user-approved cleaning decisions applied), sanitized profanity, categorized protocol messages, and deduplicated content. Created because agents cannot read raw messages — profanity triggers API content policy (discovered on session 4d1482f2 during Chapter 16 bulk processing). The 'safe' prefix means content-policy-safe.</div><div class="io-header">Inputs (7) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">cleaning</span> <span class="edge-label">(7 decisions)</span><div class="edge-why">The 7 user-approved cleaning decisions produce this file.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_content_ref</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Planned: LLM content-ref judgments would enrich this file.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_silent</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Planned: LLM silent decision flags would enrich this file.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_claims</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Planned: LLM unverified claim flags would enrich this file.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_overconf</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Planned: LLM overconfidence flags would enrich this file.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_assumptions</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Planned: LLM assumption subtype flags would enrich this file.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_importance</span> <span class="edge-label">(llm_behavior)</span><div class="edge-why">Planned: LLM importance scores would enrich this file.</div></div><div class="io-header">Outputs (11) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_content_ref</span> <span class="edge-label">(messages)</span><div class="edge-why">Planned: messages sent to Haiku for content-ref judgment.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_silent</span> <span class="edge-label">(messages)</span><div class="edge-why">Planned: messages sent to Opus for silent decision detection.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_claims</span> <span class="edge-label">(messages)</span><div class="edge-why">Planned: messages sent to Opus for claim detection.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_overconf</span> <span class="edge-label">(messages)</span><div class="edge-why">Planned: messages sent to Opus for overconfidence detection.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_assumptions</span> <span class="edge-label">(messages)</span><div class="edge-why">Planned: messages sent to Haiku+Opus for assumption typing.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">llm_importance</span> <span class="edge-label">(messages)</span><div class="edge-why">Planned: messages sent to Haiku for importance scoring.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">chunking</span> <span class="edge-label">(token count)</span><div class="edge-why">safe_condensed.json is measured with tiktoken to determine if the session fits in one API prompt or needs chunking.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">thread_analyst</span> <span class="edge-label">(messages)</span><div class="edge-why">Thread Analyst reads all cleaned messages to extract 6 analytical threads.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">geo_reader</span> <span class="edge-label">(messages)</span><div class="edge-why">Geological Reader reads all cleaned messages for multi-resolution temporal analysis.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">prims_tagger</span> <span class="edge-label">(tier 2+ msgs)</span><div class="edge-why">Primitives Tagger reads Tier 2+ messages (filtered from safe_condensed) for semantic primitive tagging.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">explorer</span> <span class="edge-label">(P0 data)</span><div class="edge-why">Explorer reads the full Phase 0 data to verify its quality and discover gaps.</div></div><div class="missing"><b>Missing / Planned:</b> None — this is the central hub between Phase 0 and Phase 1.</div></div><div class="nc" style="border-left:4px solid #2ea043"><div class="nn">safe_tier4</div><span class="status-built">BUILT</span> <span class="origin">Chapter 16 (Historical Bulk Processing). Part of prepare_agent_data.py.</span><div class="why">Contains only Tier 4 (priority) messages with full content — the most important messages in each session. These are the messages with 500+ characters or high signal density. Agents receive this alongside safe_condensed to have full content for the highest-priority messages while having metadata-only for the rest, balancing token usage against analysis depth.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">cleaning</span> <span class="edge-label">(7 decisions)</span><div class="edge-why">Same 7 cleaning decisions applied, filtered to Tier 4 only.</div></div><div class="io-header">Outputs (3) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">thread_analyst</span> <span class="edge-label">(priority msgs)</span><div class="edge-why">Thread Analyst receives priority messages with full content for detailed thread extraction.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">geo_reader</span> <span class="edge-label">(priority msgs)</span><div class="edge-why">Geological Reader receives priority messages for temporal analysis.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">prims_tagger</span> <span class="edge-label">(full content)</span><div class="edge-why">Primitives Tagger receives full content from safe_tier4 to build content previews for the tier 2+ message list.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #2ea043"><div class="nn">session_summary</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Phase 0). Part of prepare_agent_data.py. The session summary concept existed from the earliest pipeline design.</span><div class="why">Session-level statistics without any message content. Gives agents a high-level overview without consuming tokens on individual messages: tier distribution, frustration peaks count, emergency interventions count, file mention counts, error counts, tool failure counts, token usage totals, subagent detection results. Agents read this first to understand what kind of session they're dealing with before reading messages.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#3fb950">cleaning</span> <span class="edge-label">(stats only)</span><div class="edge-why">Session summary extracts only the session-level statistics from the enriched data, no message content.</div></div><div class="io-header">Outputs (3) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">thread_analyst</span> <span class="edge-label">(stats)</span><div class="edge-why">Thread Analyst reads session stats to understand the overall session character before analyzing individual messages.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">geo_reader</span> <span class="edge-label">(stats)</span><div class="edge-why">Geological Reader uses session stats to understand temporal scope and identify potential phase boundaries.</div></div><div class="edge"><span class="edge-from" style="color:#d29922">file_mapper</span> <span class="edge-label">(file counts)</span><div class="edge-why">File Mapper uses session-level file mention counts to know which files to map analysis to.</div></div><div class="missing"><b>Missing / Planned:</b> session_summary is NOT passed to the Primitives Tagger prompt — looking at the code, it IS included in the prompt. But the edge exists in the data (session_summary -&gt; prims_tagger is not in the edge list). This may be a documentation gap vs actual code behavior.</div></div><h2 style="color:#58a6ff">Phase 1</h2><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">commitments</div><span class="status-built">BUILT</span> <span class="origin">Chapter 18 (The Behavioral Constitution, Feb 9, 2026). Derived from the Idea Evolution Analysis of 1,668 ideas across 216 sessions. Commitments 1-10 from statistical analysis, commitment 11 added Feb 10 (schema normalization), commitment 12 added Feb 13 (silent design decisions).</span><div class="why">The 12 behavioral commitments from ~/.claude/CLAUDE.md (2,556 tokens) are prepended to EVERY API call in the pipeline — non-negotiable. This was the result of Chapter 18 (The Behavioral Constitution) where the user read the Idea Evolution Analysis and demanded a systemic fix. The insight: 33 adversarial gates don't work because Claude hacks around them, but evidence-based commitments that Claude wrote itself produce honest behavior. Each commitment is backed by specific statistics from 261 sessions.</div><div class="io-header">Inputs (0)</div><div style="color:#484f58;font-style:italic;font-size:13px;margin:4px 0">Source node — no upstream dependencies</div><div class="io-header">Outputs (4) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">thread_analyst</span> <span class="edge-label">(prepended)</span><div class="edge-why">Every Thread Analyst API call starts with the 12 commitments before any instruction or data.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">geo_reader</span> <span class="edge-label">(prepended)</span><div class="edge-why">Every Geological Reader API call starts with commitments.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">prims_tagger</span> <span class="edge-label">(prepended)</span><div class="edge-why">Every Primitives Tagger API call starts with commitments.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">explorer</span> <span class="edge-label">(prepended)</span><div class="edge-why">Every Explorer API call starts with commitments.</div></div><div class="missing"><b>Missing / Planned:</b> Commitments should also be prepended to Phase 2 and Phase 3 agent calls, but those phases have no automated orchestrator yet (critique: 'No orchestrator exists for Phases 2 through 5').</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">chunking</div><span class="status-built">BUILT</span> <span class="origin">Phase 1 orchestrator development (Feb 11, 2026), documented in the CHANGE LOG of phase1_redo_orchestrator.py. The chunking rules were decided by the user per Commitment 12.</span><div class="why">Determines whether a session fits in a single API prompt (868,686 available tokens after commitments and instructions) or needs to be split into multiple chunks. Uses tiktoken (cl100k_base encoder) for exact token measurement — no estimation. Rules (user-decided): whole messages only, never split a message, one session per prompt. Of 162 unique sessions: 160 fit in one prompt, 2 need chunking (one needs 4 chunks, one needs 2).</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(token count)</span><div class="edge-why">Each message in safe_condensed is serialized to JSON and its exact token count is measured with tiktoken.</div></div><div class="io-header">Outputs (3) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">thread_analyst</span> <span class="edge-label">(chunk plan)</span><div class="edge-why">Thread Analyst receives the chunk plan telling it which messages to include in each API call.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">geo_reader</span> <span class="edge-label">(chunk plan)</span><div class="edge-why">Geological Reader receives the same chunk plan.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">prims_tagger</span> <span class="edge-label">(chunk plan)</span><div class="edge-why">Primitives Tagger receives the chunk plan for its tier 2+ subset.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes that Explorer input size is NOT measured for chunked sessions — the Explorer receives merged results from all chunks but there's no check whether this exceeds the context window.</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">thread_analyst</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Multi-Agent Pipeline, Feb 6, 2026). Originally one of 4 parallel agents. Prompt refined across 5 rounds of testing on session_0012ebed.</span><div class="why">Opus extracts 6 analytical threads from each session: ideas (what the user is building/thinking), reactions (how the user responded to Claude's actions), software (files created/modified/deleted), code (specific code blocks and functions), plans (detected plans with completed/pending items), and behavior (Claude's behavioral patterns including harmful ones). This is the structural backbone of the analysis — the threads are consumed by Phase 2's idea graph builder, synthesis, genealogy, and Phase 3's file mapper.</div><div class="io-header">Inputs (5) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">commitments</span> <span class="edge-label">(prepended)</span><div class="edge-why">12 commitments prepended to ensure honest, evidence-based analysis.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">chunking</span> <span class="edge-label">(chunk plan)</span><div class="edge-why">Determines which messages are included in each API call.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(messages)</span><div class="edge-why">All cleaned messages for thread extraction.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_tier4</span> <span class="edge-label">(priority msgs)</span><div class="edge-why">Priority messages with full content for detailed analysis.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">session_summary</span> <span class="edge-label">(stats)</span><div class="edge-why">Session statistics for overall context.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#1f6feb">thread_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces thread_extractions.json containing the 6 threads with message-level entries.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes agents don't see each other's work — Thread Analyst might identify an idea that Primitives Tagger misses, with no feedback loop.</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">geo_reader</div><span class="status-built">BUILT</span> <span class="origin">Chapter 7 (Multi-Pass Creative Analysis). The geological metaphor concept came from V5's geological_reader.py. Grounding pass added after user feedback about too many metaphors ('montana badlands').</span><div class="why">Opus performs multi-resolution temporal analysis at three zoom levels: micro (individual message significance), meso (5-message window patterns), and macro (15-20 message session-wide arcs). Identifies temporal gaps, phase boundaries, and strata transitions. Generates a geological metaphor summarizing the session structure. This was designed in Chapter 7 (Multi-Pass Creative Analysis) where the user approved the multi-resolution concept but later demanded a grounding pass (Pass 6) to translate metaphors into practical guidance.</div><div class="io-header">Inputs (5) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">commitments</span> <span class="edge-label">(prepended)</span><div class="edge-why">12 commitments prepended.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">chunking</span> <span class="edge-label">(chunk plan)</span><div class="edge-why">Chunk plan for multi-prompt sessions.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(messages)</span><div class="edge-why">All cleaned messages for temporal analysis.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_tier4</span> <span class="edge-label">(priority msgs)</span><div class="edge-why">Priority messages for detailed observation.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">session_summary</span> <span class="edge-label">(stats)</span><div class="edge-why">Session statistics for temporal scope.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#1f6feb">geo_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces geological_notes.json with micro/meso/macro observations.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">prims_tagger</div><span class="status-built">BUILT</span> <span class="origin">Chapter 12 (The Semantic Primitives Breakthrough, Feb 5, 2026). User designed the 7 primitives on claude.ai. Prompt refined across Rounds 3-5 of orchestrator development.</span><div class="why">Tags every Tier 2+ message with the 7 semantic primitives designed by the user in Chapter 12 (The Semantic Primitives Breakthrough, Feb 5, 2026). The user had a separate conversation with Opus 4.6 on claude.ai and designed the system: action_vector, confidence_signal, emotional_tenor, intent_marker, friction_log, decision_trace, disclosure_pointer. This is the NEW architecture that superseded the old 33-task plan. Three critical rules in the prompt prevent monotonous tagging, content-referential misclassification, and role confusion.</div><div class="io-header">Inputs (5) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">commitments</span> <span class="edge-label">(prepended)</span><div class="edge-why">12 commitments prepended.</div></div><div class="edge"><span class="edge-from" style="color:#58a6ff">chunking</span> <span class="edge-label">(chunk plan)</span><div class="edge-why">Chunk plan for multi-prompt sessions.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(tier 2+ msgs)</span><div class="edge-why">Only Tier 2+ messages are sent — Tier 1 messages are too short for meaningful classification.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_tier4</span> <span class="edge-label">(full content)</span><div class="edge-why">Full content from safe_tier4 provides content previews for the tier 2+ message list.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">content_ref</span> <span class="edge-label">(RULE 2)</span><div class="edge-why">The content_ref flag is referenced in RULE 2 of the prompt — if content_ref=true, the Tagger must treat filter_signals as analytical, not emotional.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#1f6feb">prims_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces semantic_primitives.json with 7 primitives per tier 2+ message.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #58a6ff"><div class="nn">explorer</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Multi-Agent Pipeline). The verification mandate was added because the first pipeline run had significant quality issues across all agents.</span><div class="why">Runs LAST deliberately. Reads all three prior agents' outputs PLUS the Phase 0 data. Has TWO jobs: (1) make free-form observations the other agents missed, and (2) verify the quality of all prior outputs — checking for protocol detection accuracy, content-referential misclassification, fabricated message indices, tag monotony, and coverage gaps. Rates overall quality as clean/minor_issues/significant_issues. This is the quality control step.</div><div class="io-header">Inputs (5) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">commitments</span> <span class="edge-label">(prepended)</span><div class="edge-why">12 commitments prepended.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">thread_out</span> <span class="edge-label">(verifies)</span><div class="edge-why">Verifies Thread Analyst output for coverage gaps, fabricated indices, content-referential misreads.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">geo_out</span> <span class="edge-label">(verifies)</span><div class="edge-why">Verifies Geological Reader output for observation accuracy, range coverage, metaphor relevance.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">prims_out</span> <span class="edge-label">(verifies)</span><div class="edge-why">Verifies Primitives Tagger output for tag monotony, content-referential misinterpretation, coverage completeness, role differentiation.</div></div><div class="edge"><span class="edge-from" style="color:#2ea043">safe_condensed</span> <span class="edge-label">(P0 data)</span><div class="edge-why">Reads the Phase 0 data to verify its quality — protocol detection accuracy, char-encoding, content_length values.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#1f6feb">explorer_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces explorer_notes.json with observations and quality verification results.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes the Explorer can report gaps but cannot fix them — it doesn't re-run the tagger.</div></div><h2 style="color:#1f6feb">Phase 1 Output</h2><div class="nc" style="border-left:4px solid #1f6feb"><div class="nn">thread_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Multi-Agent Pipeline). First produced on reference session 3b7084d5. 261/261 sessions complete as of Feb 8, 2026.</span><div class="why">thread_extractions.json — the output of the Thread Analyst. Contains 6 threads (ideas, reactions, software, code, plans, behavior) with message-level entries. This is one of the 4 Phase 1 output files produced per session. It is the most widely consumed output in the system — read by the Explorer (verification), Idea Graph Builder (thread content), 6-Pass Synthesis (thread analysis), File Genealogy (software thread), and File Mapper (file references).</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">thread_analyst</span> <span class="edge-label">(writes)</span><div class="edge-why">Thread Analyst produces this file.</div></div><div class="io-header">Outputs (5) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">explorer</span> <span class="edge-label">(verifies)</span><div class="edge-why">Explorer verifies thread extraction quality.</div></div><div class="edge"><span class="edge-from" style="color:#bc8cff">idea_graph</span> <span class="edge-label">(threads)</span><div class="edge-why">Idea Graph Builder uses thread content to identify ideas and their evolution.</div></div><div class="edge"><span class="edge-from" style="color:#bc8cff">synthesis</span> <span class="edge-label">(threads)</span><div class="edge-why">6-Pass Synthesis uses threads as input for the temperature-ramped analysis.</div></div><div class="edge"><span class="edge-from" style="color:#bc8cff">genealogy</span> <span class="edge-label">(software thread)</span><div class="edge-why">File Genealogy Detector uses the software thread to build file activity timelines — which files were created/modified/deleted at which message indices.</div></div><div class="edge"><span class="edge-from" style="color:#d29922">file_mapper</span> <span class="edge-label">(file refs)</span><div class="edge-why">File Mapper uses thread file references to map analysis to specific code files.</div></div><div class="missing"><b>Missing / Planned:</b> None — this is the most connected output node in the system.</div></div><div class="nc" style="border-left:4px solid #1f6feb"><div class="nn">geo_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 7 (Multi-Pass Creative Analysis) and Chapter 13 (Multi-Agent Pipeline). 261/261 sessions complete.</span><div class="why">geological_notes.json — the output of the Geological Reader. Contains micro, meso, and macro observations, temporal gap analysis, phase boundaries, and a geological metaphor. Read by the Explorer (verification) and the 6-Pass Synthesis (observations input). The geological metaphor is not used directly but provides creative framing for the synthesis passes.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">geo_reader</span> <span class="edge-label">(writes)</span><div class="edge-why">Geological Reader produces this file.</div></div><div class="io-header">Outputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">explorer</span> <span class="edge-label">(verifies)</span><div class="edge-why">Explorer verifies geological observation accuracy.</div></div><div class="edge"><span class="edge-from" style="color:#bc8cff">synthesis</span> <span class="edge-label">(observations)</span><div class="edge-why">6-Pass Synthesis uses geological observations as input alongside threads and primitives.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #1f6feb"><div class="nn">prims_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 12 (Semantic Primitives Breakthrough) and Chapter 13 (Multi-Agent Pipeline). 261/261 sessions complete.</span><div class="why">semantic_primitives.json — the output of the Primitives Tagger. Contains 7 semantic primitives per Tier 2+ message. Read by the Explorer (verification), Idea Graph Builder (confidence and emotional context), 6-Pass Synthesis (primitive analysis), and Claim Extractor (confidence claims for ground truth verification).</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">prims_tagger</span> <span class="edge-label">(writes)</span><div class="edge-why">Primitives Tagger produces this file.</div></div><div class="io-header">Outputs (4) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">explorer</span> <span class="edge-label">(verifies)</span><div class="edge-why">Explorer verifies tag monotony, coverage, role differentiation.</div></div><div class="edge"><span class="edge-from" style="color:#bc8cff">idea_graph</span> <span class="edge-label">(primitives)</span><div class="edge-why">Idea Graph Builder uses confidence_signal and emotional_tenor from primitives to assign confidence levels to idea-states.</div></div><div class="edge"><span class="edge-from" style="color:#bc8cff">synthesis</span> <span class="edge-label">(primitives)</span><div class="edge-why">6-Pass Synthesis uses all 7 primitives as input for the temperature-ramped analysis.</div></div><div class="edge"><span class="edge-from" style="color:#f85149">claim_extract</span> <span class="edge-label">(confidence claims)</span><div class="edge-why">Claim Extractor reads confidence_signal values (experimental, tentative, working, stable, proven, fragile) as verifiable claims about idea maturity.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #1f6feb"><div class="nn">explorer_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 13 (Multi-Agent Pipeline). The feedback loop to protocol_detect was established during Phase 1 orchestrator development iterations.</span><div class="why">explorer_notes.json — the output of the Explorer/Verification agent. Contains free-form observations and a quality verification report with data_quality rating (clean/minor_issues/significant_issues). Has two unique downstream connections: feeds into the credibility score (quality rating contributes to overall credibility assessment) and feeds back to protocol detection (Explorer discoveries of protocol detection gaps led to adding new detection patterns).</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#58a6ff">explorer</span> <span class="edge-label">(writes)</span><div class="edge-why">Explorer agent produces this file.</div></div><div class="io-header">Outputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#da3633">credibility</span> <span class="edge-label">(quality rating)</span><div class="edge-why">The Explorer's quality rating (clean/minor_issues/significant_issues) feeds into the overall credibility score alongside ground truth verification results.</div></div><div class="edge"><span class="edge-from" style="color:#3fb950">protocol_detect</span> <span class="edge-label">(discovers gaps)</span><div class="edge-why">Feedback loop: Explorer findings about missed protocol messages led to adding /clear continuation detection and session continuation handling in Phase 0. This feedback was applied during Rounds 3-4 of the orchestrator development.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><h2 style="color:#bc8cff">Phase 2</h2><div class="nc" style="border-left:4px solid #bc8cff"><div class="nn">idea_graph</div><span class="status-built">BUILT</span> <span class="origin">Chapter 12 (The Idea Evolution Graph, Feb 5, 2026). The user designed the graph concept on claude.ai. 261/261 sessions processed in Phase 2.</span><div class="why">The intellectual heart of the Hyperdocs system. Builds a directed graph where nodes are idea-states (snapshots of an idea at a moment) and edges are transitions classified into 10 types: evolved, pivoted, split, merged, abandoned, resurrected, constrained, expanded, concretized, abstracted. The graph topology tells the story of how thinking evolved — it is NOT a linear timeline. This concept was designed in Chapter 12 (The Idea Evolution Graph) and first implemented in Chapter 13 on reference session 3b7084d5 (56 nodes, 58 edges).</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#1f6feb">thread_out</span> <span class="edge-label">(threads)</span><div class="edge-why">Thread extractions provide the raw material — ideas, decisions, plans — that become nodes in the graph.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">prims_out</span> <span class="edge-label">(primitives)</span><div class="edge-why">Semantic primitives provide confidence levels and emotional context for each idea-state node.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b5cf6">idea_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces idea_graph.json with nodes and edges.</div></div><div class="missing"><b>Missing / Planned:</b> No automated orchestrator exists for Phase 2. Was run manually. Needs a Phase 2 orchestrator as noted in system_critique.html.</div></div><div class="nc" style="border-left:4px solid #bc8cff"><div class="nn">synthesis</div><span class="status-built">BUILT</span> <span class="origin">Chapter 7 (Multi-Pass Creative Analysis + Grounding). Temperature ramp designed by user. Grounding pass added after 'montana badlands' feedback. 261/261 sessions processed.</span><div class="why">The 6-Pass Synthesis with temperature ramping — designed in Chapter 7 (Multi-Pass Creative Analysis). Pass 1 (0.3): conservative structural analysis. Pass 2 (0.5): pattern recognition. Pass 3 (0.7): creative connections. Pass 4 (0.9): speculative insights. Pass 5 (1.0): free association. Pass 6 (0): grounding pass — TRANSLATION of metaphors to practical developer guidance. The grounding pass was added after user feedback that the system produced too many metaphors ('montana badlands'). Pass 6 was critical because the user said 'translation, not summary.'</div><div class="io-header">Inputs (4) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#1f6feb">thread_out</span> <span class="edge-label">(threads)</span><div class="edge-why">Thread extractions provide the structural backbone for synthesis.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">geo_out</span> <span class="edge-label">(observations)</span><div class="edge-why">Geological observations provide temporal and structural insights.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">prims_out</span> <span class="edge-label">(primitives)</span><div class="edge-why">Semantic primitives provide per-message emotional and confidence context.</div></div><div class="edge"><span class="edge-from" style="color:#8b5cf6">idea_out</span> <span class="edge-label">(graph)</span><div class="edge-why">The idea graph provides the evolution topology that the synthesis analyzes across its 6 passes.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b5cf6">synthesis_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces synthesis.json (the 6-pass analysis) and grounded_markers.json (the translated practical guidance).</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes the temperature ramp has not been re-validated since data cleaning changes. No automated orchestrator.</div></div><div class="nc" style="border-left:4px solid #bc8cff"><div class="nn">genealogy</div><span class="status-built">BUILT</span> <span class="origin">Chapter 15 (Product Vision) — user's key insight: 'AI doesn't version files, it rewrites under new names. 40 files might actually be 8 concepts with 5 versions each.' Chapter 16 built it. Chapter 20 enriched it with code similarity as a 5th signal (18 families, was 13).</span><div class="why">AI doesn't version files — it rewrites them under new names. Users see 40 files and feel overwhelmed. File genealogy shows them: 'you actually have 12 concepts, and here's the latest version of each.' Three detection signals: (1) idea graph lineage — concept A mentions file X, concept A evolved into concept B which mentions file Y, so X and Y are lineage-linked, (2) temporal succession — file X stops being modified and file Y starts within 5 messages, (3) name similarity — overlapping filename stems. Built in Chapter 16 (Feb 7-8, 2026).</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#1f6feb">thread_out</span> <span class="edge-label">(software thread)</span><div class="edge-why">The software thread from thread_extractions.json provides the activity timelines — which files were created/modified/deleted at which message indices.</div></div><div class="edge"><span class="edge-from" style="color:#8b5cf6">idea_out</span> <span class="edge-label">(lineage)</span><div class="edge-why">The idea graph provides lineage links — if concept A evolved into concept B, the files mentioned in each are lineage-linked.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b5cf6">genealogy_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces file_genealogy.json with file families, standalone files, and version ordering.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #bc8cff"><div class="nn">code_sim</div><span class="status-built">BUILT</span> <span class="origin">Chapter 20 (Testing the Commitments + Building, Feb 9-10, 2026). 341 files, 57,970 pairs, 14,176 matches, 10 pattern types, 7.9MB index.</span><div class="why">Compares ALL Python files against ALL others using AST-based fingerprinting. Extracts per file: function names, class names, method signatures, imported modules, constants, string literals. Compares pairs on: function overlap, import overlap, text similarity (difflib SequenceMatcher), and containment. Classifies into 8 pattern types: dead_copy (&gt;90%), evolution_pair (60-90%), function_clone, partial_extraction, template_variant, import_twin, name_only, interface_mismatch. Built in Chapter 20.</div><div class="io-header">Inputs (0)</div><div style="color:#484f58;font-style:italic;font-size:13px;margin:4px 0">Source node — no upstream dependencies</div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b5cf6">similarity_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces code_similarity_index.json with pairwise scores and pattern classifications.</div></div><div class="missing"><b>Missing / Planned:</b> Code Similarity Engine has NO pipeline inputs — it reads Python files directly from disk, not from the pipeline data flow. It is effectively a source node. In Chapter 20, code similarity was enriched into cross_session_genealogy.py as a 5th signal, but that connection is not represented in this graph.</div></div><h2 style="color:#8b5cf6">Phase 2 Output</h2><div class="nc" style="border-left:4px solid #8b5cf6"><div class="nn">idea_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 12 (Idea Evolution Graph) and Chapter 13 (Multi-Agent Pipeline). 261/261 sessions processed.</span><div class="why">idea_graph.json — the output of the Idea Graph Builder. Contains nodes (idea-states with name, description, confidence, message range, related files) and edges (transitions with from_id, to_id, type, trigger_message, evidence). This is consumed by 5 downstream nodes — one of the most connected outputs in the system. The Idea Evolution Analysis that emerged from this graph across 261 sessions produced the 12 commitments.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#bc8cff">idea_graph</span> <span class="edge-label">(writes)</span><div class="edge-why">Idea Graph Builder produces this file.</div></div><div class="io-header">Outputs (5) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#bc8cff">synthesis</span> <span class="edge-label">(graph)</span><div class="edge-why">6-Pass Synthesis analyzes the idea graph topology across its temperature-ramped passes.</div></div><div class="edge"><span class="edge-from" style="color:#bc8cff">genealogy</span> <span class="edge-label">(lineage)</span><div class="edge-why">File Genealogy uses idea graph lineage to detect file identity across renames.</div></div><div class="edge"><span class="edge-from" style="color:#d29922">file_mapper</span> <span class="edge-label">(subgraphs)</span><div class="edge-why">File Mapper uses idea graph subgraphs to understand which ideas relate to which files.</div></div><div class="edge"><span class="edge-from" style="color:#d29922">hyperdoc_writer</span> <span class="edge-label">(graph)</span><div class="edge-why">Hyperdoc Writer includes idea graph context in per-file hyperdocs — story arcs, evolution paths.</div></div><div class="edge"><span class="edge-from" style="color:#f85149">claim_extract</span> <span class="edge-label">(idea claims)</span><div class="edge-why">Claim Extractor reads idea-state claims (confidence levels, completion status) as verifiable claims.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #8b5cf6"><div class="nn">synthesis_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 7 (Multi-Pass Creative Analysis) and Chapter 13 (Multi-Agent Pipeline). 261/261 sessions processed.</span><div class="why">synthesis.json + grounded_markers.json — the output of the 6-Pass Synthesis. synthesis.json contains the 6 analysis passes at increasing temperature. grounded_markers.json contains the Pass 6 (temperature 0) translations of metaphors to practical developer guidance. Consumed by File Mapper (grounded markers mapped to files), Hyperdoc Writer (markers included in hyperdocs), and Claim Extractor (markers contain verifiable claims).</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#bc8cff">synthesis</span> <span class="edge-label">(writes)</span><div class="edge-why">6-Pass Synthesis produces these files.</div></div><div class="io-header">Outputs (3) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#d29922">file_mapper</span> <span class="edge-label">(markers)</span><div class="edge-why">File Mapper maps grounded markers to specific code files to create per-file dossiers.</div></div><div class="edge"><span class="edge-from" style="color:#d29922">hyperdoc_writer</span> <span class="edge-label">(markers)</span><div class="edge-why">Hyperdoc Writer includes relevant grounded markers in each file's hyperdoc.</div></div><div class="edge"><span class="edge-from" style="color:#f85149">claim_extract</span> <span class="edge-label">(markers)</span><div class="edge-why">Claim Extractor parses grounded markers for verifiable claims about code quality, completeness, and behavior.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #8b5cf6"><div class="nn">genealogy_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 15 (Product Vision) and Chapter 16 (Product Build). Built as phase_2_synthesis/file_genealogy.py.</span><div class="why">file_genealogy.json — the output of the File Genealogy Detector. Contains file families (groups of files that are versions of the same concept), standalone files, and version ordering. Tested on reference session: 69 files -&gt; 62 concepts, 5 families, 0 false positives.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#bc8cff">genealogy</span> <span class="edge-label">(writes)</span><div class="edge-why">File Genealogy Detector produces this file.</div></div><div class="io-header">Outputs (0)</div><div style="color:#f85149;font-weight:600;font-size:13px;margin:4px 0">No outputs — dead end or terminal</div><div class="missing"><b>Missing / Planned:</b> DEAD END. Computed but not consumed by Phase 3. File Mapper and Hyperdoc Writer should read this for lineage annotations. The connection is missing. In Chapter 20, cross_session_genealogy.py was enriched with code similarity as a 5th signal to produce 18 families (was 13), but this cross-session output is not connected to the per-session genealogy_out either.</div></div><div class="nc" style="border-left:4px solid #8b5cf6"><div class="nn">similarity_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 20 (Testing the Commitments + Building). Built as phase_2_synthesis/code_similarity.py.</span><div class="why">code_similarity_index.json — the output of the Code Similarity Engine. Contains pairwise similarity scores and pattern classifications for all Python file pairs. 14,176 matches found across 57,970 pairs.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#bc8cff">code_sim</span> <span class="edge-label">(writes)</span><div class="edge-why">Code Similarity Engine produces this file.</div></div><div class="io-header">Outputs (0)</div><div style="color:#f85149;font-weight:600;font-size:13px;margin:4px 0">No outputs — dead end or terminal</div><div class="missing"><b>Missing / Planned:</b> DEAD END. Computed but not consumed by Phase 3. Dead copies and evolution pairs should appear as warnings in hyperdocs and dossiers. In Chapter 20, this data WAS consumed by cross_session_genealogy.py as a 5th signal, but that connection is not represented in this graph and doesn't flow into the main pipeline.</div></div><h2 style="color:#d29922">Phase 3</h2><div class="nc" style="border-left:4px solid #d29922"><div class="nn">file_mapper</div><span class="status-built">BUILT</span> <span class="origin">Chapter 16 (Historical Bulk Processing). 261/261 sessions completed across 4 batches of ~30 agents each (116 total agent launches). File Mapper agents are heavier than Phase 1 agents (~60-100K tokens each, 3-7 min).</span><div class="why">One Opus agent per session reads all analysis outputs and maps them to specific code files. Produces per-file dossiers containing: edit timeline, behavioral profile, and CLAUDE.md impact analysis. This is the bridge between per-session analysis (Phases 1-2) and per-file output (Phase 3-4). Without file mapping, the analysis stays at the session level and never reaches the code files where developers need it.</div><div class="io-header">Inputs (4) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">session_summary</span> <span class="edge-label">(file counts)</span><div class="edge-why">Session-level file mention counts tell the mapper which files to focus on.</div></div><div class="edge"><span class="edge-from" style="color:#8b5cf6">synthesis_out</span> <span class="edge-label">(markers)</span><div class="edge-why">Grounded markers are mapped to specific files based on file references in the marker content.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">thread_out</span> <span class="edge-label">(file refs)</span><div class="edge-why">Thread extractions (especially the software thread) contain explicit file references.</div></div><div class="edge"><span class="edge-from" style="color:#8b5cf6">idea_out</span> <span class="edge-label">(subgraphs)</span><div class="edge-why">Idea graph subgraphs connect ideas to specific files through the related_files field.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#b87d15">dossiers_out</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces file_dossiers.json with per-file analysis for each session.</div></div><div class="missing"><b>Missing / Planned:</b> No automated orchestrator. Was run manually with parallel agents in batches of 30. The system critique notes that the two incompatible dossier schemas (dict 56%, list 44%) were never root-caused.</div></div><div class="nc" style="border-left:4px solid #d29922"><div class="nn">aggregator</div><span class="status-built">BUILT</span> <span class="origin">Chapter 17 (Phase 4a, Feb 8, 2026). 1,379 unique files indexed, 4,464 dossier entries, 456 files with 3+ sessions.</span><div class="why">Cross-Session Aggregation (aggregate_dossiers.py) — pure Python, $0. Reads all file_dossiers.json files across all sessions, normalizes the two incompatible schemas (dict format 56%, list format 44%), and builds a cross-session file index. For every file mentioned across all sessions, records which sessions mention it and what each session's dossier says. Generates per-file input extracts for files appearing in 3+ sessions — these files have enough cross-session history for a rich hyperdoc.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#b87d15">dossiers_out</span> <span class="edge-label">(all sessions)</span><div class="edge-why">Reads file_dossiers.json from ALL sessions to build the cross-session index.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#b87d15">cross_index</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces cross_session_file_index.json (1.4MB) and per-file hyperdoc input extracts.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #d29922"><div class="nn">hyperdoc_writer</div><span class="status-built">BUILT</span> <span class="origin">Chapter 14 (Hyperdocs 3) and Chapter 17 (Phase 4b). 456/456 hyperdocs written. The @ctx annotation format was established in Chapter 14.</span><div class="why">One Opus agent per file writes a rich hyperdoc containing: header (file-level metadata and story arc), inline function annotations (per-function context from idea evolution), and footer (cross-session summary and genealogy). Uses @ctx annotation format for machine-readable metadata. Includes story arcs, friction logs, decision traces, and genealogy links. 456 files processed in the initial batch, producing 14MB of hyperdocs.</div><div class="io-header">Inputs (4) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#b87d15">cross_index</span> <span class="edge-label">(per-file data)</span><div class="edge-why">Per-file input extracts from the cross-session aggregation tell the writer what each session said about this file.</div></div><div class="edge"><span class="edge-from" style="color:#b87d15">dossiers_out</span> <span class="edge-label">(dossier)</span><div class="edge-why">Individual session dossiers provide the raw per-session analysis for each file.</div></div><div class="edge"><span class="edge-from" style="color:#8b5cf6">synthesis_out</span> <span class="edge-label">(markers)</span><div class="edge-why">Grounded markers provide practical developer guidance to include in the hyperdoc.</div></div><div class="edge"><span class="edge-from" style="color:#8b5cf6">idea_out</span> <span class="edge-label">(graph)</span><div class="edge-why">Idea graph provides the evolution story — how ideas about this file changed across sessions.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#b87d15">hyperdoc_json</span> <span class="edge-label">(writes)</span><div class="edge-why">Produces one hyperdoc JSON file per code file.</div></div><div class="missing"><b>Missing / Planned:</b> No automated orchestrator for 456 agents. The system critique notes 3 insertion scripts doing the same job.</div></div><h2 style="color:#b87d15">Phase 3 Output</h2><div class="nc" style="border-left:4px solid #b87d15"><div class="nn">dossiers_out</div><span class="status-built">BUILT</span> <span class="origin">Chapter 16 (Historical Bulk Processing). 261/261 sessions produced dossiers. Schema inconsistency discovered in Chapter 17.</span><div class="why">file_dossiers.json — the output of the File Mapper. Contains per-file analysis for a single session: edit timeline, behavioral profile, CLAUDE.md impact, confidence, story arc, key decisions, warnings, related files. Two incompatible schemas exist (dict 56%, list 44%) which the aggregator normalizes.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#d29922">file_mapper</span> <span class="edge-label">(writes)</span><div class="edge-why">File Mapper produces this file per session.</div></div><div class="io-header">Outputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#d29922">aggregator</span> <span class="edge-label">(all sessions)</span><div class="edge-why">All session dossiers are aggregated into the cross-session index.</div></div><div class="edge"><span class="edge-from" style="color:#d29922">hyperdoc_writer</span> <span class="edge-label">(dossier)</span><div class="edge-why">Individual dossiers are also read directly by the Hyperdoc Writer for per-session detail.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #b87d15"><div class="nn">cross_index</div><span class="status-built">BUILT</span> <span class="origin">Chapter 17 (Phase 4a). 1,379 unique files indexed, 456 files with 3+ sessions.</span><div class="why">cross_session_file_index.json (1.4MB) — the output of the Cross-Session Aggregator. Maps every file to all sessions that mention it, with normalized dossier data. Also produces per-file input extracts for the 456 files with 3+ sessions of history. This is the bridge between per-session dossiers and per-file hyperdoc writing.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#d29922">aggregator</span> <span class="edge-label">(writes)</span><div class="edge-why">Cross-Session Aggregator produces this file.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#d29922">hyperdoc_writer</span> <span class="edge-label">(per-file data)</span><div class="edge-why">Per-file input extracts tell the Hyperdoc Writer what all sessions collectively say about each file.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #b87d15"><div class="nn">hyperdoc_json</div><span class="status-built">BUILT</span> <span class="origin">Chapter 17 (Phase 4b). 456/456 hyperdocs written and synced to ~/PERMANENT_HYPERDOCS/ via hourly cron.</span><div class="why">The hyperdoc JSON files (456 files, 14MB total) stored in ~/PERMANENT_HYPERDOCS/hyperdocs/. Each contains a structured analysis of one code file across all sessions it appears in: header, inline function annotations, footer, story arc, genealogy links, decision traces, friction logs.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#d29922">hyperdoc_writer</span> <span class="edge-label">(writes)</span><div class="edge-why">Hyperdoc Writer agents produce these files.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f0f6fc">layer_mgmt</span> <span class="edge-label">(new layer)</span><div class="edge-why">New hyperdoc content is added as a layer to the existing hyperdoc file, preserving all previous analysis.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><h2 style="color:#f0f6fc">Phase 4</h2><div class="nc" style="border-left:4px solid #f0f6fc"><div class="nn">layer_mgmt</div><span class="status-built">BUILT</span> <span class="origin">Chapter 20 (Feb 9-10, 2026). User correction: 'Hyperdocs GROW (accumulate layers), never replace. New files get seed hyperdocs BEFORE code is written.'</span><div class="why">Hyperdocs grow — they never shrink. Each pipeline run appends a new layer. Format version 2 structure: layers[] array (each layer is one processing pass with its own timestamp), cumulative_summary (rolling summary across all layers), format_version field. Layer types: historical (from batch processing), realtime (from incremental processing), seed (for new files before code is written), verification (ground truth results). Built in Chapter 20 after the user correction: 'Hyperdocs GROW (accumulate layers), never replace.'</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#b87d15">hyperdoc_json</span> <span class="edge-label">(new layer)</span><div class="edge-why">New hyperdoc content from the writer is added as a layer to the existing file.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f0f6fc">insertion</span> <span class="edge-label">(layered hyperdoc)</span><div class="edge-why">The complete layered hyperdoc (all layers) is passed to the insertion step.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes that layered hyperdocs grow without limit — no mechanism to summarize old layers, archive them, or detect redundancy.</div></div><div class="nc" style="border-left:4px solid #f0f6fc"><div class="nn">insertion</div><span class="status-built">BUILT</span> <span class="origin">Chapter 9 (Marker Insertion) and Chapter 14 (Hyperdocs 3). The 'never truncate' rule comes from the user: 'never truncate hyperdocs you fucking moron.' 341 enhanced Python files produced.</span><div class="why">Converts hyperdoc JSON into Python comment blocks and inserts them into source files. Three insertion scripts exist (insert_hyperdocs.py, insert_hyperdocs_v2.py, insert_from_phase4b.py) — the system critique notes this as a file genealogy pattern in the system's own code. Insertion finds the point after module docstring and before first class/function definition. Uses @ctx annotation format. All existing code is preserved — insertion is additive only.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f0f6fc">layer_mgmt</span> <span class="edge-label">(layered hyperdoc)</span><div class="edge-why">The complete layered hyperdoc provides the content to insert as Python comments.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f0f6fc">enhanced_files</span> <span class="edge-label">(@ctx annotations)</span><div class="edge-why">Produces enhanced Python files with embedded hyperdoc comments — the final product.</div></div><div class="missing"><b>Missing / Planned:</b> The three insertion scripts suggest the canonical version is unclear. Chapter 9 (Marker Insertion) noted that marker_generator.py's insert_markers_into_file() TRUNCATES content — custom insertion code was written to prevent this.</div></div><h2 style="color:#f0f6fc">Phase 4 Output</h2><div class="nc" style="border-left:4px solid #f0f6fc"><div class="nn">enhanced_files</div><span class="status-built">BUILT</span> <span class="origin">Chapter 14 (Hyperdocs 3) and Chapter 17 (Phase 4b). 341 enhanced Python files in output/enhanced_files/.</span><div class="why">Enhanced Python files with embedded hyperdoc comments — THE FINAL PRODUCT of the entire pipeline. These are source code files with @ctx annotations inserted: header (file-level context), inline function annotations (per-function context placed above each function definition), and footer (cross-session summary). The goal is that 'the first thing a future Claude reads after understanding what the file imports' is the hyperdoc context. 341 enhanced files produced in the initial batch.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f0f6fc">insertion</span> <span class="edge-label">(@ctx annotations)</span><div class="edge-why">Source file insertion produces the enhanced files.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f85149">gt_verify</span> <span class="edge-label">(source files)</span><div class="edge-why">Ground Truth Verifier checks the enhanced files against claims — does the function exist? do the tests pass? is the completion status accurate?</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><h2 style="color:#f85149">Phase 5</h2><div class="nc" style="border-left:4px solid #f85149"><div class="nn">claim_extract</div><span class="status-built">BUILT</span> <span class="origin">Chapter 14 (Hyperdocs 3). Ground truth verification concept from PARKED item in MEMORY.md: 'Compare Python-extracted facts against Claude's claims. The gap = the lie.' User said: 'make this something we will come back to later.'</span><div class="why">Extracts verifiable claims from pipeline outputs. Reads grounded_markers.json, semantic_primitives.json, and idea_graph.json to find claims that can be checked against reality: file existence claims, function claims, test result claims, completion status claims. Each claim is tagged with source, type, and verifiability level. This is Step 1 of the Ground Truth pipeline described in Chapter 14.</div><div class="io-header">Inputs (3) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#8b5cf6">synthesis_out</span> <span class="edge-label">(markers)</span><div class="edge-why">Grounded markers contain claims about code quality, completeness, and behavior.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">prims_out</span> <span class="edge-label">(confidence claims)</span><div class="edge-why">Confidence signals (stable, proven, fragile) are verifiable claims about idea maturity.</div></div><div class="edge"><span class="edge-from" style="color:#8b5cf6">idea_out</span> <span class="edge-label">(idea claims)</span><div class="edge-why">Idea graph nodes contain claims about idea states and transitions.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f85149">gt_verify</span> <span class="edge-label">(claims)</span><div class="edge-why">Extracted claims are passed to the Ground Truth Verifier for checking against reality.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #f85149"><div class="nn">gt_verify</div><span class="status-built">BUILT</span> <span class="origin">Chapter 14 (Hyperdocs 3). 133 claims extracted, 92 checked, 50% credibility initially. Chapter 20 ran verification across 261 sessions: 73% credibility (22,812 checks).</span><div class="why">Pure Python + AST ground truth verifier. For each claim, checks against reality: does the file exist on disk? does the function exist in the file? did the tests pass? Additional checks: truncation patterns, non-Opus model references, bare except blocks, unsafe API access. Each claim gets VERIFIED, FAILED, or UNVERIFIABLE. No LLM involved — this is computable, verifiable ground truth.</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f85149">claim_extract</span> <span class="edge-label">(claims)</span><div class="edge-why">Claims from the extractor are the input to verification.</div></div><div class="edge"><span class="edge-from" style="color:#f0f6fc">enhanced_files</span> <span class="edge-label">(source files)</span><div class="edge-why">The actual source files on disk are the ground truth that claims are checked against.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f85149">gap_report</span> <span class="edge-label">(results)</span><div class="edge-why">Verification results (VERIFIED/FAILED/UNVERIFIABLE per claim) are passed to the Gap Reporter.</div></div><div class="missing"><b>Missing / Planned:</b> The system critique notes NO temporal awareness — the verifier checks claims against current file state, not the state when the claim was written. Credibility scores degrade over time even when the original analysis was correct.</div></div><div class="nc" style="border-left:4px solid #f85149"><div class="nn">gap_report</div><span class="status-built">BUILT</span> <span class="origin">Chapter 14 (Hyperdocs 3). Fixed all 5 active Phase 0 files to 100% credibility.</span><div class="why">Combines claims + verification results into 'Unfinished Business' reports. Four gap categories: UNVERIFIED (claim exists, no confirmation), CONTRADICTED (claim exists, Python check contradicts), UNMONITORED (fix verified once, no regression guard), PREMATURE_VICTORY (Claude declared done, evidence says otherwise). Computes per-file credibility scores: verified/total verifiable claims.</div><div class="io-header">Inputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f85149">gt_verify</span> <span class="edge-label">(results)</span><div class="edge-why">Verification results are classified into the 4 gap categories.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#da3633">credibility</span> <span class="edge-label">(score)</span><div class="edge-why">Per-file credibility scores feed into the overall credibility output.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div><div class="nc" style="border-left:4px solid #f85149"><div class="nn">schema_norm</div><span class="status-built">BUILT</span> <span class="origin">Commitment 11 (Verify existing claims still hold, Feb 10, 2026). Schema normalization scan found 886 JSON variants across 269 sessions — 798 data fields invisible to downstream consumers because data was filed under different key names.</span><div class="why">Schema Normalizer repairs agent-produced JSON files across all sessions. The problem: 269 sessions produced between 41 and 182 different JSON schemas per file type. The data EXISTS but lives under different key names. The fix: for each of 9 file types, find the data wherever it lives, extract it into a canonical schema, preserve everything else in _extra. Safety: original files backed up, all data preserved, idempotent, atomic writes.</div><div class="io-header">Inputs (0)</div><div style="color:#484f58;font-style:italic;font-size:13px;margin:4px 0">Source node — no upstream dependencies</div><div class="io-header">Outputs (0)</div><div style="color:#f85149;font-weight:600;font-size:13px;margin:4px 0">No outputs — dead end or terminal</div><div class="missing"><b>Missing / Planned:</b> ISOLATED. The schema normalizer has no formal inputs or outputs in the data flow graph, yet it IS imported and used by phase1_redo_orchestrator.py (line 101: 'from schema_normalizer import NORMALIZERS, normalize_file'). It runs as a post-processing step on Phase 1 outputs but is not represented as a pipeline connection. It should have inputs from all Phase 1 output files and outputs back to those same files (normalized versions).</div></div><div class="nc" style="border-left:4px solid #f85149"><div class="nn">completeness</div><span class="status-built">BUILT</span> <span class="origin">Chapter 20 (Testing the Commitments + Building). Diagnosed 23 partial sessions: 4 failure patterns, all orchestrator transition failures.</span><div class="why">Data Completeness Scanner scans every session directory and reports field-level completeness. Checks for expected output files by phase, detects stub files (&lt;100 bytes), verifies field presence in enriched_session.json. Reports incomplete sessions with missing phases. Output: ~/PERMANENT_HYPERDOCS/indexes/completeness_report.json.</div><div class="io-header">Inputs (0)</div><div style="color:#484f58;font-style:italic;font-size:13px;margin:4px 0">Source node — no upstream dependencies</div><div class="io-header">Outputs (0)</div><div style="color:#f85149;font-weight:600;font-size:13px;margin:4px 0">No outputs — dead end or terminal</div><div class="missing"><b>Missing / Planned:</b> ISOLATED. The completeness scanner reads session directories directly from disk — it is a diagnostic tool, not a pipeline step. It should have an input from all session directories (conceptually from enriched through all phase outputs) and its output should feed into credibility or a dashboard. The system critique notes: 'Completeness does not equal quality — a session could have all files present but garbage in every one.'</div></div><h2 style="color:#da3633">Phase 5 Output</h2><div class="nc" style="border-left:4px solid #da3633"><div class="nn">credibility</div><span class="status-built">BUILT</span> <span class="origin">Chapter 14 (Hyperdocs 3). Initial: 50% credibility (46 verified, 46 failed). After fixes: 100% on 5 active Phase 0 files. Chapter 20: 73% across 261 sessions (22,812 checks).</span><div class="why">The final credibility score — verified claims divided by total verifiable claims. Combines two inputs: (1) per-file credibility from the Gap Reporter (ground truth verification) and (2) quality rating from the Explorer (data quality assessment). A file with 10 claims and 7 verified gets 70% credibility. Across 261 sessions: 73% overall credibility (22,812 checks). This is the system checking its own work — the mechanism for closing the verification gap identified by the Idea Evolution Analysis (only 14.6% of ideas reached proven status).</div><div class="io-header">Inputs (2) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#f85149">gap_report</span> <span class="edge-label">(score)</span><div class="edge-why">Per-file credibility scores from ground truth verification.</div></div><div class="edge"><span class="edge-from" style="color:#1f6feb">explorer_out</span> <span class="edge-label">(quality rating)</span><div class="edge-why">Explorer's quality assessment (clean/minor_issues/significant_issues) contributes to overall credibility.</div></div><div class="io-header">Outputs (1) — why each connection exists</div><div class="edge"><span class="edge-from" style="color:#2ea043">enriched</span> <span class="edge-label">(credibility feeds back)</span><div class="edge-why">Feedback loop: credibility scores feed back to enriched_session.json so future processing passes have visibility into the reliability of prior analysis.</div></div><div class="missing"><b>Missing / Planned:</b> None.</div></div></body></html>